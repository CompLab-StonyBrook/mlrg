<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>MLRG</title><link href="https://complab-stonybrook.github.io/mlrg/" rel="alternate"></link><link href="https://complab-stonybrook.github.io/mlrg/feeds/all.atom.xml" rel="self"></link><id>https://complab-stonybrook.github.io/mlrg/</id><updated>2023-04-04T16:50:44-04:00</updated><entry><title>Scott on rule interactions in phonology at 1:30 pm (Apr 7)</title><link href="https://complab-stonybrook.github.io/mlrg/news/2023-spring/scott-on-rule-interactions-in-phonology-at-130-pm-apr-7.html" rel="alternate"></link><published>2023-04-04T00:00:00-04:00</published><updated>2023-04-04T16:50:44-04:00</updated><author><name>Zhengxiang (Jack) Wang</name></author><id>tag:complab-stonybrook.github.io,2023-04-04:/mlrg/news/2023-spring/scott-on-rule-interactions-in-phonology-at-130-pm-apr-7.html</id><summary type="html">&lt;p&gt;Interacting phonological processes are interesting for phonological theory because they often lead to opaque surface forms: forms where a process applied in an environment where it shouldn't have (overapplication) and forms where a process does not apply even though it looks like it should (underapplication). In my presentation I'll review …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Interacting phonological processes are interesting for phonological theory because they often lead to opaque surface forms: forms where a process applied in an environment where it shouldn't have (overapplication) and forms where a process does not apply even though it looks like it should (underapplication). In my presentation I'll review different ways people have talked about process interaction (rules, OT, Two-Level Phonology, automata) and then discuss some new ideas using logical transductions. Specifically, I discuss some possibilities for non-compositional process interaction.&lt;/p&gt;</content><category term="2023-Spring"></category></entry><entry><title>Gary gives a brief history of the logic of time at 1:30 pm (Mar 31)</title><link href="https://complab-stonybrook.github.io/mlrg/news/2023-spring/gary-gives-a-brief-history-of-the-logic-of-time-at-130-pm-mar-31.html" rel="alternate"></link><published>2023-03-22T00:00:00-04:00</published><updated>2023-03-28T14:13:12-04:00</updated><author><name>Zhengxiang (Jack) Wang</name></author><id>tag:complab-stonybrook.github.io,2023-03-22:/mlrg/news/2023-spring/gary-gives-a-brief-history-of-the-logic-of-time-at-130-pm-mar-31.html</id><summary type="html">&lt;p&gt;Gary will give a talk titled "A Brief History of the Logic of Time: Some Paradoxes from A to Z" this Friday. His talk will begin with a puzzle inspired by Erich Friedman [1998]. You can click &lt;a href="https://docs.google.com/document/d/1hcbSBlT62_9hpwdwRb9_YfqYwHDdZmUr/edit?usp=share_link&amp;amp;ouid=109948658946118555134&amp;amp;rtpof=true&amp;amp;sd=true"&gt;here&lt;/a&gt; to read the puzzle with a picture of triplets or check the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Gary will give a talk titled "A Brief History of the Logic of Time: Some Paradoxes from A to Z" this Friday. His talk will begin with a puzzle inspired by Erich Friedman [1998]. You can click &lt;a href="https://docs.google.com/document/d/1hcbSBlT62_9hpwdwRb9_YfqYwHDdZmUr/edit?usp=share_link&amp;amp;ouid=109948658946118555134&amp;amp;rtpof=true&amp;amp;sd=true"&gt;here&lt;/a&gt; to read the puzzle with a picture of triplets or check the &lt;a href="https://erich-friedman.github.io/puzzle/"&gt;Puzzle Palace&lt;/a&gt; of Erich Friedman for more examples.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Puzzle&lt;/strong&gt;: Tweedledum, Tweedledee, and Tweedledoo are identical triplets.&lt;/p&gt;
&lt;p&gt;Each either tells the truth all day long or tells lies all day long.  &lt;/p&gt;
&lt;p&gt;Tweedledum lies only on Mondays and Tuesdays. &lt;/p&gt;
&lt;p&gt;Tweedledee lies only on Wednesdays and Thursdays.&lt;/p&gt;
&lt;p&gt;Tweedledoo lies only Fridays, and Saturdays. &lt;/p&gt;
&lt;p&gt;On Sundays everyone tells the truth. &lt;/p&gt;
&lt;p&gt;Alice meets the three of them and calls them A, B, and C since she can’t tell them apart. &lt;/p&gt;
&lt;p&gt;This is what Alice heard: &lt;/p&gt;
&lt;p&gt;A says, “I will lie tomorrow.” &lt;/p&gt;
&lt;p&gt;B says, “I lied yesterday, and I will lie tomorrow.”&lt;/p&gt;
&lt;p&gt;C says, “Today isn’t Tuesday.”&lt;/p&gt;
&lt;p&gt;What day of the week did the conversation take place? Who are A, B, and C?&lt;/p&gt;</content><category term="2023-Spring"></category></entry><entry><title>Magda on learning sequential functions with features at 1:30 pm (Mar 24)</title><link href="https://complab-stonybrook.github.io/mlrg/news/2023-spring/magda-on-learning-sequential-functions-with-features-at-130-pm-mar-24.html" rel="alternate"></link><published>2023-03-22T00:00:00-04:00</published><updated>2023-03-22T19:48:37-04:00</updated><author><name>Zhengxiang (Jack) Wang</name></author><id>tag:complab-stonybrook.github.io,2023-03-22:/mlrg/news/2023-spring/magda-on-learning-sequential-functions-with-features-at-130-pm-mar-24.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;Topic&lt;/strong&gt;: Learning sequential functions with sub-symbolic properties&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Details&lt;/strong&gt;: It has been shown that morphophonological processes represented with subsequential functions can be learnt from finite samples of data (&lt;a href="http://proceedings.mlr.press/v34/jardine14a.pdf"&gt;Jardine et al. 2014&lt;/a&gt;). We show that the size of such a sample can be significantly reduced if we change the representation of …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Topic&lt;/strong&gt;: Learning sequential functions with sub-symbolic properties&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Details&lt;/strong&gt;: It has been shown that morphophonological processes represented with subsequential functions can be learnt from finite samples of data (&lt;a href="http://proceedings.mlr.press/v34/jardine14a.pdf"&gt;Jardine et al. 2014&lt;/a&gt;). We show that the size of such a sample can be significantly reduced if we change the representation of the data from strings to features.&lt;/p&gt;</content><category term="2023-Spring"></category></entry><entry><title>Jeff on Noisy Learning at 1:30 pm (Mar 10)</title><link href="https://complab-stonybrook.github.io/mlrg/news/2023-spring/jeff-on-noisy-learning-at-130-pm-mar-10.html" rel="alternate"></link><published>2023-03-06T00:00:00-05:00</published><updated>2023-03-06T16:19:22-05:00</updated><author><name>Zhengxiang (Jack) Wang</name></author><id>tag:complab-stonybrook.github.io,2023-03-06:/mlrg/news/2023-spring/jeff-on-noisy-learning-at-130-pm-mar-10.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;Topic&lt;/strong&gt;: Identification in the limit from positive data with noise&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Details&lt;/strong&gt;: We consider the problem of identifying formal languages in the limit when the presentations of positive data are corrupted by noise. Two kinds of noise are considered separately: when the data systematically omits positive examples and when negative examples …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;strong&gt;Topic&lt;/strong&gt;: Identification in the limit from positive data with noise&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Details&lt;/strong&gt;: We consider the problem of identifying formal languages in the limit when the presentations of positive data are corrupted by noise. Two kinds of noise are considered separately: when the data systematically omits positive examples and when negative examples intrude into the data presentation. It is shown that while noise is problematic in general, we can identify conditions under which string extension learning can succeed or succeed as well as anyone could reasonably expect.&lt;/p&gt;</content><category term="2023-Spring"></category></entry><entry><title>Kenneth on String-based Syntax at 1:30 pm (Mar 3)</title><link href="https://complab-stonybrook.github.io/mlrg/news/2023-spring/kenneth-on-string-based-syntax-at-130-pm-mar-3.html" rel="alternate"></link><published>2023-02-27T00:00:00-05:00</published><updated>2023-02-27T20:21:34-05:00</updated><author><name>Zhengxiang (Jack) Wang</name></author><id>tag:complab-stonybrook.github.io,2023-02-27:/mlrg/news/2023-spring/kenneth-on-string-based-syntax-at-130-pm-mar-3.html</id><summary type="html">&lt;p&gt;We often say that syntactic dependencies are in the computational classes SL and TSL over trees (Graf 2018 et seq). But what does that mean? Actually, there several ways to generalize the string classes to trees. One of these involves command strings (c-strings), which encode the c-commanders of some node …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We often say that syntactic dependencies are in the computational classes SL and TSL over trees (Graf 2018 et seq). But what does that mean? Actually, there several ways to generalize the string classes to trees. One of these involves command strings (c-strings), which encode the c-commanders of some node in a specific derivational order. In this case the tree languages are constrained by SL and TSL grammars over the c-strings they contain.&lt;/p&gt;
&lt;p&gt;But which c-strings should we consider? All of them? No, we should consider only those which trace the &lt;em&gt;spine&lt;/em&gt; of a tree, or of some subtree. Graf and De Santo (2019) show how a sensing tree automaton, a kind of top-down automaton with a look-ahead window of 1, has about the right power for syntax. Furthermore, it is possible to algorithmically construct such an automaton which recognizes only trees that contain licit c-strings, and only consider the ones that matter.&lt;/p&gt;
&lt;p&gt;This means that we can effectively decompose a tree language into string languages, which can be visualized easily with string finite state automata, and compared with analogous patterns in phonology. I illustrate this with discussing the following:&lt;/p&gt;
&lt;p&gt;- SL: phonotactics / selection, functional hierarchy&lt;/p&gt;
&lt;p&gt;- TSL: vowel harmony / agreement, case&lt;/p&gt;</content><category term="2023-Spring"></category></entry><entry><title>Jack on RNN seq2seq models learning alignments at 1:30 pm (Feb 24)</title><link href="https://complab-stonybrook.github.io/mlrg/news/2023-spring/jack-on-rnn-seq2seq-models-learning-alignments-at-130-pm-feb-24.html" rel="alternate"></link><published>2023-02-21T00:00:00-05:00</published><updated>2023-02-21T18:47:48-05:00</updated><author><name>Zhengxiang (Jack) Wang</name></author><id>tag:complab-stonybrook.github.io,2023-02-21:/mlrg/news/2023-spring/jack-on-rnn-seq2seq-models-learning-alignments-at-130-pm-feb-24.html</id><summary type="html">&lt;p&gt;Sequence-to-sequence (seq2seq) models are a class of neural network models that learn the mapping between given input and target sequences. These models take an encoder-decoder structure where the encoder reads the inputs and passes the encoded information to the decoder, and the decoder decodes the encoded information and writes outputs …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Sequence-to-sequence (seq2seq) models are a class of neural network models that learn the mapping between given input and target sequences. These models take an encoder-decoder structure where the encoder reads the inputs and passes the encoded information to the decoder, and the decoder decodes the encoded information and writes outputs. &lt;/p&gt;
&lt;p&gt;Jack's focus is on Recurrent Neural Networks (RNNs) seq2seq models, whose encoder and decoder are both RNNs, in learning four transduction tasks that require alignments learning. These tasks are: identity, reversal, total reduplication, and input specified reduplication. Jack will talk about the learning capabilities of RNN seq2seq models, and the complexity of learning them that is different from the traditional FST*-theoretic characterizations.&lt;/p&gt;
&lt;p&gt;*FST: Finite State Transducer&lt;/p&gt;</content><category term="2023-Spring"></category></entry><entry><title>No meeting this Friday (Feb 17)</title><link href="https://complab-stonybrook.github.io/mlrg/news/2023-spring/no-meeting-this-friday-feb-17.html" rel="alternate"></link><published>2023-02-12T00:00:00-05:00</published><updated>2023-02-12T19:35:39-05:00</updated><author><name>Zhengxiang (Jack) Wang</name></author><id>tag:complab-stonybrook.github.io,2023-02-12:/mlrg/news/2023-spring/no-meeting-this-friday-feb-17.html</id><summary type="html">&lt;p&gt;We will not be meeting this Friday, because of a Blitztalk that takes place 1:00-2:00 pm on the same day. The Blitztalk is part of the virtual open house for the next cohort of PhD students, which, as Thomas emphasizes, "&lt;ins&gt;&lt;cite&gt;is perhaps the most important event of the …&lt;/cite&gt;&lt;/ins&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;We will not be meeting this Friday, because of a Blitztalk that takes place 1:00-2:00 pm on the same day. The Blitztalk is part of the virtual open house for the next cohort of PhD students, which, as Thomas emphasizes, "&lt;ins&gt;&lt;cite&gt;is perhaps the most important event of the day, and a strong turnout means a lot for recruitment.&lt;/cite&gt;&lt;/ins&gt;" So if you do have time, please consider going to the Blitztalk!&lt;/p&gt;</content><category term="2023-Spring"></category></entry><entry><title>Jeff on Piecewise Local Expressions at 1:30 pm (Feb 10)</title><link href="https://complab-stonybrook.github.io/mlrg/news/2023-spring/jeff-on-piecewise-local-expressions-at-130-pm-feb-10.html" rel="alternate"></link><published>2023-02-07T00:00:00-05:00</published><updated>2023-02-07T14:37:37-05:00</updated><author><name>Zhengxiang (Jack) Wang</name></author><id>tag:complab-stonybrook.github.io,2023-02-07:/mlrg/news/2023-spring/jeff-on-piecewise-local-expressions-at-130-pm-feb-10.html</id><summary type="html">&lt;p&gt;Piecewise Local Expressions (Lambert 2022) are a kind of regular expression language for describing certain kinds of formal languages easily using the notion of substring and subsequence containment. These will be reviewed in the beginning. Then we will spend time thinking how to develop a similar expression language (i.e …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Piecewise Local Expressions (Lambert 2022) are a kind of regular expression language for describing certain kinds of formal languages easily using the notion of substring and subsequence containment. These will be reviewed in the beginning. Then we will spend time thinking how to develop a similar expression language (i.e. one based on containment) to facilitate the construction of tree languages, with an eye towards expressing linguistically relevant generalizations.&lt;/p&gt;</content><category term="2023-Spring"></category></entry></feed>